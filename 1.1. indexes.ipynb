{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd23dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "from timm import create_model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import medmnist\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.linalg import inv\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "from torch_geometric.nn import LabelPropagation\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from dppy.finite_dpps import FiniteDPP\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.linalg import inv\n",
    "import seaborn as sns\n",
    "import medmnist\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import community\n",
    "import community.community_louvain as community\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import kneighbors_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model = vit_model.to(device)\n",
    "vit_model.eval()\n",
    "\n",
    "@torch.no_grad()    \n",
    "def extract_features(loader, model, device):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for images, target in tqdm(loader, desc=\"Extracting Features\"):\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(images) # batch size, embedding size\n",
    "        features.append(output)\n",
    "        labels.append(target)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    return features, labels\n",
    "\n",
    "train_loader, val_loader, test_loader = load_datasets(img_size, batch_size, shuffle_train=False)\n",
    "\n",
    "train_features, train_labels = extract_features(train_loader, vit_model, device)\n",
    "val_features, val_labels = extract_features(val_loader, vit_model, device)\n",
    "test_features, test_labels = extract_features(test_loader, vit_model, device)\n",
    "\n",
    "train_features.shape, val_features.shape, test_features.shape\n",
    "\n",
    "torch.save(train_features, \"vit_train_features.pth\")\n",
    "torch.save(train_labels, \"vit_train_labels.pth\")\n",
    "torch.save(val_features, \"vit_val_features.pth\")\n",
    "torch.save(val_labels, \"vit_val_labels.pth\")\n",
    "torch.save(test_features, \"vit_test_features.pth\")\n",
    "torch.save(test_labels, \"vit_test_labels.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = timm.create_model('vgg16', pretrained=True, num_classes=0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_model = vgg_model.to(device)\n",
    "vgg_model.eval()\n",
    "\n",
    "train_loader, val_loader, test_loader = load_datasets(img_size, batch_size, shuffle_train=False)\n",
    "\n",
    "train_features_vgg, train_labels_vgg = extract_features(train_loader, vgg_model, device)\n",
    "val_features_vgg, val_labels_vgg = extract_features(val_loader, vgg_model, device)\n",
    "test_features_vgg, test_labels_vgg = extract_features(test_loader, vgg_model, device)\n",
    "\n",
    "torch.save(train_features_vgg, \"vgg_train_features.pth\")\n",
    "torch.save(train_labels_vgg, \"vgg_train_labels.pth\")\n",
    "torch.save(val_features_vgg, \"vgg_val_features.pth\")\n",
    "torch.save(val_labels_vgg, \"vgg_val_labels.pth\")\n",
    "torch.save(test_features_vgg, \"vgg_test_features.pth\")\n",
    "torch.save(test_labels_vgg, \"vgg_test_labels.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_coreset_selection(dataset, percentage):\n",
    "    indices = []\n",
    "    labels = dataset.labels.flatten()  # labels shape (N,)\n",
    "    for cls in np.unique(labels):\n",
    "        class_indices = np.where(labels == cls)[0]\n",
    "        sample_count = max(1, int(len(class_indices) * (percentage / 100.0))) \n",
    "        selected = np.random.choice(class_indices, size=sample_count, replace=False)\n",
    "        indices.extend(selected)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "\n",
    "def load_datasubsets(img_size=img_size, batch_size=batch_size, coreset_percentage=None):\n",
    "    \"\"\"\n",
    "    Loads datasets and, if coreset_percentage is provided, applies random coreset selection on the training set.\n",
    "    \"\"\"\n",
    "    train_dataset = NumpyDataset(os.path.join(path, 'train_images.npy'),\n",
    "                                 os.path.join(path, 'train_labels.npy'),\n",
    "                                 train_transform)\n",
    "    if coreset_percentage is not None:\n",
    "        train_dataset = random_coreset_selection(train_dataset, coreset_percentage)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    val_dataset = NumpyDataset(os.path.join(path, 'val_images.npy'),\n",
    "                               os.path.join(path, 'val_labels.npy'),\n",
    "                               val_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    test_dataset = NumpyDataset(os.path.join(path, 'test_images.npy'),\n",
    "                                os.path.join(path, 'test_labels.npy'),\n",
    "                                val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def compute_subset_class_counts(subset):\n",
    "    labels = [int(subset.dataset.labels[i].item()) for i in subset.indices] # scalar for each label\n",
    "    return dict(Counter(labels))\n",
    "\n",
    "def compute_class_percentage(original_counts, subset_counts):\n",
    "    percentages = {}\n",
    "    for cls in original_counts:\n",
    "        original_count = original_counts[cls]\n",
    "        subset_count = subset_counts.get(cls, 0)\n",
    "        percentages[cls] = (subset_count / original_count) * 100\n",
    "    return percentages\n",
    "\n",
    "percentages_list = [0.1, 1, 10]\n",
    "for percentage in percentages_list:\n",
    "    print(f\"\\n\\n======================= PERCENTAGE {percentage}% =======================\")\n",
    "    train_loader, val_loader, test_loader = load_datasubsets(img_size, batch_size, percentage)\n",
    "    \n",
    "    train_class_counts = compute_class_counts(os.path.join(path, 'train_labels.npy'))\n",
    "    train_subset_counts = compute_subset_class_counts(train_loader.dataset)\n",
    "    train_subset_percentages = compute_class_percentage(train_class_counts, train_subset_counts)\n",
    "\n",
    "    print('Train class counts:', train_class_counts)\n",
    "    print('Train subset counts:', train_subset_counts)\n",
    "    print('Train subset percentages:', train_subset_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_subset(model, train_loader, val_loader, device, optimizer, scheduler, scaler, \n",
    "                       num_epochs=num_epochs, accumulation_steps=4, patience=5):\n",
    "    metrics_log = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": [],\n",
    "        \"val_f1\": []\n",
    "    }\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        for step, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\")):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels) / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                try:\n",
    "                    scaler.step(optimizer)\n",
    "                except AssertionError:\n",
    "                    optimizer.step()\n",
    "                try:\n",
    "                    scaler.update()\n",
    "                except AssertionError:\n",
    "                    pass\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "            _, predicted = outputs.max(1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        if (step + 1) % accumulation_steps != 0:\n",
    "            try:\n",
    "                scaler.step(optimizer)\n",
    "            except AssertionError:\n",
    "                optimizer.step()\n",
    "            try:\n",
    "                scaler.update()\n",
    "            except AssertionError:\n",
    "                pass\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        train_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_labels, val_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "        metrics_log[\"train_loss\"].append(train_loss)\n",
    "        metrics_log[\"train_accuracy\"].append(train_accuracy)\n",
    "        metrics_log[\"train_f1\"].append(train_f1)\n",
    "        metrics_log[\"val_loss\"].append(val_loss)\n",
    "        metrics_log[\"val_accuracy\"].append(val_accuracy)\n",
    "        metrics_log[\"val_f1\"].append(val_f1)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"vgg_random_derma_best.pth\")\n",
    "            print(\"Validation loss improved. Model saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Final Train Loss:     {metrics_log['train_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Train Accuracy: {metrics_log['train_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Train F1:       {metrics_log['train_f1'][-1]:.4f}\")\n",
    "    print(f\"Final Val Loss:       {metrics_log['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Val Accuracy:   {metrics_log['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Val F1:         {metrics_log['val_f1'][-1]:.4f}\")\n",
    "    \n",
    "    return metrics_log\n",
    "\n",
    "def run_random_coreset_experiments(coreset_percentages=[0.1, 1, 10],\n",
    "                                   seeds=[42, 43, 45],\n",
    "                                   num_epochs=100,\n",
    "                                   learning_rate=0.001,\n",
    "                                   batch_size=128,\n",
    "                                   img_size=224):\n",
    "    overall_results = {}\n",
    "    for cp in coreset_percentages:\n",
    "        print(f\"\\n\\n======================= Random Coreset Percentage: {cp}% =======================\")\n",
    "        results = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n\\n----------------------- SEED {seed} -----------------------\")\n",
    "            set_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            train_loader, val_loader, test_loader = load_datasubsets(img_size, batch_size, coreset_percentage=cp)\n",
    "            \n",
    "            model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "            model = model.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "            metrics_log = train_model_subset(model, train_loader, val_loader, device,\n",
    "                                             optimizer, scheduler, scaler,\n",
    "                                             num_epochs=num_epochs)\n",
    "            \n",
    "            final_val_acc = metrics_log[\"val_accuracy\"][-1]\n",
    "            final_val_f1  = metrics_log[\"val_f1\"][-1]\n",
    "            results.append((final_val_acc, final_val_f1))\n",
    "        \n",
    "        results = np.array(results)\n",
    "        means = results.mean(axis=0)\n",
    "        stds  = results.std(axis=0)\n",
    "        print(\"\\n\\n======================= SUMMARY for {}% =======================\".format(cp))\n",
    "        print(f\"Validation Accuracy: mean={means[0]:.4f}, std={stds[0]:.4f}\")\n",
    "        print(f\"Validation F1:       mean={means[1]:.4f}, std={stds[1]:.4f}\")\n",
    "        overall_results[cp] = {\"mean\": means, \"std\": stds}\n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_coreset_selection(features, labels, percentages, random_state=seed):\n",
    "    if torch.is_tensor(features):\n",
    "        features_np = features.cpu().numpy()\n",
    "    else:\n",
    "        features_np = np.array(features)\n",
    "    if torch.is_tensor(labels):\n",
    "        labels_np = labels.cpu().numpy()\n",
    "    else:\n",
    "        labels_np = np.array(labels)\n",
    "    labels_np = labels_np.flatten() \n",
    "\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    unique_classes = np.unique(labels_np)\n",
    "    dict_of_subsets = {}\n",
    "\n",
    "    for p in percentages:\n",
    "        selected_indices = []\n",
    "\n",
    "        for c in unique_classes:\n",
    "            class_indices = np.where(labels_np == c)[0]\n",
    "            class_features = features_np[class_indices]\n",
    "            n_samples = len(class_indices)\n",
    "\n",
    "\n",
    "            k = int(np.floor((p / 100.0) * n_samples))\n",
    "            k = max(1, min(k, n_samples))  # min 1\n",
    "\n",
    "            if k > 1:\n",
    "                kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10)\n",
    "                kmeans.fit(class_features)\n",
    "                centroids = kmeans.cluster_centers_\n",
    "                labels_km = kmeans.labels_\n",
    "            else:\n",
    "                centroids = [np.mean(class_features, axis=0)]\n",
    "                labels_km = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "            for cluster_id in range(k):\n",
    "                cluster_member_indices = np.where(labels_km == cluster_id)[0]\n",
    "                if len(cluster_member_indices) == 0:\n",
    "                    continue  # Skip empty clusters.\n",
    "                distances = np.linalg.norm(\n",
    "                    class_features[cluster_member_indices] - centroids[cluster_id],\n",
    "                    axis=1\n",
    "                )\n",
    "                rep_idx_in_cluster = cluster_member_indices[np.argmin(distances)]\n",
    "                selected_indices.append(class_indices[rep_idx_in_cluster])\n",
    "\n",
    "        while set(labels_np[selected_indices]) != set(unique_classes):\n",
    "            missing_classes = set(unique_classes) - set(labels_np[selected_indices])\n",
    "            for c in missing_classes:\n",
    "                fallback_idx = np.random.choice(np.where(labels_np == c)[0]).item()\n",
    "                selected_indices.append(fallback_idx)\n",
    "        selected_indices = sorted(selected_indices)\n",
    "        dict_of_subsets[p] = selected_indices\n",
    "\n",
    "    return dict_of_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ea888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_experiments_vgg_derma(kmeans_percentages=[0.1, 1, 10],\n",
    "                           seeds=[42, 43, 45],\n",
    "                           num_epochs=20,\n",
    "                           learning_rate=0.0001,\n",
    "                           batch_size=16,\n",
    "                           img_size=224):\n",
    "    overall_results = {}\n",
    "\n",
    "    train_features = torch.load(\"vgg_derma_train_features.pth\")\n",
    "    train_labels = torch.load(\"vgg_derma_train_labels.pth\")\n",
    "    \n",
    "    for kp in kmeans_percentages:\n",
    "        print(f\"\\n\\n======================= Kmeans Subset Percentage: {kp}% =======================\")\n",
    "        results = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n\\n----------------------- SEED {seed} -----------------------\")\n",
    "            set_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            selected_indices_dict = kmeans_coreset_selection(train_features, train_labels, [kp])\n",
    "            selected_indices = selected_indices_dict[kp]\n",
    "            print(f\"Number of selected samples: {len(selected_indices)}\")\n",
    "            \n",
    "            train_dataset = NumpyDataset(os.path.join(path, 'train_images.npy'),\n",
    "                                         os.path.join(path, 'train_labels.npy'),\n",
    "                                         train_transform)\n",
    "            train_subset = Subset(train_dataset, selected_indices)\n",
    "            train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "\n",
    "            val_dataset = NumpyDataset(os.path.join(path, 'val_images.npy'),\n",
    "                                       os.path.join(path, 'val_labels.npy'),\n",
    "                                       val_test_transform)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "            model = model.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "            metrics_log = train_model_subset(model, train_loader, val_loader, device,\n",
    "                                             optimizer, scheduler, scaler,\n",
    "                                             num_epochs=num_epochs)\n",
    "            final_val_acc = metrics_log[\"val_accuracy\"][-1]\n",
    "            final_val_f1  = metrics_log[\"val_f1\"][-1]\n",
    "            results.append((final_val_acc, final_val_f1))\n",
    "        \n",
    "        results = np.array(results)\n",
    "        means = results.mean(axis=0)\n",
    "        stds  = results.std(axis=0)\n",
    "        print(\"\\n\\n======================= SUMMARY for {}% =======================\".format(kp))\n",
    "        print(f\"Validation Accuracy: mean={means[0]:.4f}, std={stds[0]:.4f}\")\n",
    "        print(f\"Validation F1:       mean={means[1]:.4f}, std={stds[1]:.4f}\")\n",
    "        overall_results[kp] = {\"mean\": means, \"std\": stds}\n",
    "    return overall_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64980dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epsilon(full_features, subset_indices):\n",
    "    \"\"\"\n",
    "    Computes the minimum distance of every full feature to the nearest coreset feature.\n",
    "    Returns:\n",
    "      - min_distances: array of minimum distances for each full feature.\n",
    "      - epsilon: the maximum of these minimum distances (i.e. worst-case coverage).\n",
    "    \"\"\"\n",
    "    subset_features = full_features[subset_indices]\n",
    "    distances = pairwise_distances(full_features, subset_features) \n",
    "    min_distances = distances.min(axis=1) #for every train feature, min distance to any selected coreset sample\n",
    "    epsilon = min_distances.max()\n",
    "    return min_distances, epsilon\n",
    "\n",
    "def plot_epsilon_distribution(full_features, subset_indices, method_name=\"\", percentage=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the minimum distances from every point in the full set to the coreset.\n",
    "    A vertical line indicates the epsilon (worst-case) distance.\n",
    "    The title includes the coreset percentage and the selection method.\n",
    "    \"\"\"\n",
    "    min_distances, epsilon = compute_epsilon(full_features, subset_indices)\n",
    "    \n",
    "    if percentage is not None:\n",
    "        title_str = f\"Min Distance Distribution ({method_name}, {percentage}% coreset)\"\n",
    "    else:\n",
    "        title_str = f\"Min Distance Distribution ({method_name})\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(min_distances, bins=50, alpha=0.7)\n",
    "    plt.axvline(epsilon, color='red', linestyle='--', label=f\"Epsilon = {epsilon:.2f}\")\n",
    "    plt.xlabel(\"Minimum distance to coreset\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(title_str)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return epsilon\n",
    "\n",
    "def plot_2d_epsilon_net(full_features, subset_indices, method_name=\"\", percentage=None):\n",
    "    \"\"\"\n",
    "    Uses t-SNE to project the full features into 2D and plots all points (with low opacity)\n",
    "    along with the selected coreset points (in red).\n",
    "    The plot title includes the coreset percentage and the selection method.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    full_features_2d = tsne.fit_transform(full_features)\n",
    "    subset_features_2d = full_features_2d[subset_indices]\n",
    "    \n",
    "    if percentage is not None:\n",
    "        title_str = f\"2D Visualization of Epsilon Net ({method_name}, {percentage}% coreset)\"\n",
    "    else:\n",
    "        title_str = f\"2D Visualization of Epsilon Net ({method_name})\"\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(full_features_2d[:, 0], full_features_2d[:, 1], alpha=0.3, label=\"All Samples\")\n",
    "    plt.scatter(subset_features_2d[:, 0], subset_features_2d[:, 1], color=\"red\", label=\"Coreset Samples\")\n",
    "    plt.title(title_str)\n",
    "    plt.xlabel(\"t-SNE dimension 1\")\n",
    "    plt.ylabel(\"t-SNE dimension 2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for p in percentages:\n",
    "    print(f\"\\n\\n======================= PERCENTAGE {p}% =======================\")\n",
    "    full_train_images = np.load(os.path.join(path, 'train_images.npy'))  # shape: (N, H, W, C)\n",
    "    full_train_features = full_train_images.reshape(full_train_images.shape[0], -1)\n",
    "    \n",
    "    train_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'train_images.npy'),\n",
    "        os.path.join(path, 'train_labels.npy'),\n",
    "        train_transform \n",
    "    )\n",
    "    random_subset = random_coreset_selection(train_dataset, p)\n",
    "    random_selected_indices = random_subset.indices  \n",
    "    print(f\"Number of random selected samples: {len(random_selected_indices)}\")\n",
    "    \n",
    "\n",
    "    train_labels = np.load(os.path.join(path, 'train_labels.npy')).squeeze().astype(np.int64)\n",
    "    N = full_train_images.shape[0]\n",
    "    train_features_flat = full_train_images.reshape(N, -1)\n",
    "\n",
    "    train_features_tensor = torch.tensor(train_features_flat, dtype=torch.float32)\n",
    "    train_labels_tensor = torch.tensor(train_labels)\n",
    "    \n",
    "    kmeans_selected_indices_dict = kmeans_coreset_selection(train_features_tensor, train_labels_tensor, [p])\n",
    "    kmeans_selected_indices = kmeans_selected_indices_dict[p]\n",
    "    print(f\"Number of kmeans selected samples: {len(kmeans_selected_indices)}\")\n",
    "    \n",
    "    epsilon_random = plot_epsilon_distribution(full_train_features, random_selected_indices, method_name=\"Random Selection\")\n",
    "    plot_2d_epsilon_net(full_train_features, random_selected_indices, method_name=\"Random Selection\")\n",
    "    print(f\"Random Selection Epsilon: {epsilon_random:.2f}\")\n",
    "    \n",
    "    epsilon_kmeans = plot_epsilon_distribution(full_train_features, kmeans_selected_indices, method_name=\"Kmeans Selection\")\n",
    "    plot_2d_epsilon_net(full_train_features, kmeans_selected_indices, method_name=\"Kmeans Selection\")\n",
    "    print(f\"Kmeans Selection Epsilon: {epsilon_kmeans:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a198a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_propagation(features, alpha=0.5):\n",
    "    features = features.cpu()\n",
    "    N, d = features.shape\n",
    "    squared_norms = (features ** 2).sum(dim=1, keepdim=True)  # (N, 1)\n",
    "    d2 = squared_norms + squared_norms.t() - 2 * (features @ features.t())\n",
    "    mask = torch.ones_like(d2, dtype=torch.bool)\n",
    "    mask.fill_diagonal_(False)\n",
    "    sigma2 = d2[mask].var()  \n",
    "    A = torch.exp(-d2 / sigma2)\n",
    "    A.fill_diagonal_(0) \n",
    "    D = A.sum(dim=1)  \n",
    "    D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D + 1e-8))\n",
    "    L = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    I = torch.eye(N)\n",
    "    P = torch.inverse(I - alpha * L)\n",
    "    propagated_features = P @ features\n",
    "    return propagated_features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_feat_path = \"vit_train_features.pth\"\n",
    "    val_feat_path = \"vit_val_features.pth\"\n",
    "    test_feat_path = \"vit_test_features.pth\"\n",
    "    \n",
    "    vit_train_features = torch.load(train_feat_path)\n",
    "    vit_val_features = torch.load(val_feat_path)\n",
    "    vit_test_features = torch.load(test_feat_path)\n",
    "    \n",
    "    propagated_train_features = compute_embedding_propagation(vit_train_features, alpha=0.5)\n",
    "    propagated_val_features = compute_embedding_propagation(vit_val_features, alpha=0.5)\n",
    "    propagated_test_features = compute_embedding_propagation(vit_test_features, alpha=0.5)\n",
    "    \n",
    "    torch.save(propagated_train_features, \"propagated_train_features.pth\")\n",
    "    torch.save(propagated_val_features, \"propagated_val_features.pth\")\n",
    "    torch.save(propagated_test_features, \"propagated_test_features.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b29aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_propagation_coreset_selection_for_dataset(dataset, propagated_features, labels, percentage, alpha=0.5):\n",
    "    selected_indices = []\n",
    "    propagated_features = propagated_features.cpu()\n",
    "    labels = labels.cpu()\n",
    "    unique_labels = torch.unique(labels)\n",
    "    \n",
    "    for cls in unique_labels:\n",
    "        class_mask = (labels == cls)\n",
    "        class_indices = torch.nonzero(class_mask, as_tuple=True)[0]\n",
    "        X_c = propagated_features[class_indices]\n",
    "        n_c, d = X_c.shape\n",
    "        \n",
    "        centroid = X_c.mean(dim=0, keepdim=True)\n",
    "        centroid_sim = F.cosine_similarity(X_c, centroid, dim=-1)\n",
    "        sorted_order = torch.argsort(centroid_sim, descending=True)\n",
    "        num_to_select = max(1, int(n_c * (percentage / 100.0)))\n",
    "        selected_class_indices = class_indices[sorted_order[:num_to_select]]\n",
    "        selected_indices.append(selected_class_indices)\n",
    "    \n",
    "    selected_indices = torch.cat(selected_indices)\n",
    "    return Subset(dataset, selected_indices.cpu().numpy())\n",
    "\n",
    "def load_datasubsets_embedding_propagation(img_size=224, batch_size=64, coreset_percentage=None, \n",
    "                                            propagated_features=None, vit_labels=None):\n",
    "    train_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'train_images.npy'),\n",
    "        os.path.join(path, 'train_labels.npy'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    if coreset_percentage is not None and propagated_features is not None and vit_labels is not None:\n",
    "        train_dataset = embedding_propagation_coreset_selection_for_dataset(\n",
    "            train_dataset, propagated_features, vit_labels, coreset_percentage\n",
    "        )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'val_images.npy'),\n",
    "        os.path.join(path, 'val_labels.npy'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'test_images.npy'),\n",
    "        os.path.join(path, 'test_labels.npy'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def run_embedding_propagation_coreset_vgg_derma(coreset_percentages=[0.1, 1, 10],\n",
    "                                                  seeds=[42, 43, 45],\n",
    "                                                  num_epochs=20,\n",
    "                                                  learning_rate=0.0001,\n",
    "                                                  batch_size=16,\n",
    "                                                  img_size=224):\n",
    "    propagated_train_features = torch.load(\"propagated_vgg_derma_train_features.pth\")\n",
    "    vit_train_labels = torch.from_numpy(np.load(os.path.join(path, 'train_labels.npy'))).long()\n",
    "    \n",
    "    overall_results = {}\n",
    "    for cp in coreset_percentages:\n",
    "        print(f\"\\n\\n======================= Coreset Percentage: {cp}% =======================\")\n",
    "        results = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n\\n----------------------- SEED {seed} -----------------------\")\n",
    "            set_seed(seed)\n",
    "            train_loader, val_loader, test_loader = load_datasubsets_embedding_propagation(\n",
    "                img_size=img_size,\n",
    "                batch_size=batch_size,\n",
    "                coreset_percentage=cp,\n",
    "                propagated_features=propagated_train_features,\n",
    "                vit_labels=vit_train_labels\n",
    "            )\n",
    "            \n",
    "            model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "            model = model.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                                   factor=0.1, patience=5, verbose=True)\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "            metrics_log = train_model_subset(model, train_loader, val_loader, device,\n",
    "                                             optimizer, scheduler, scaler,\n",
    "                                             num_epochs=num_epochs)\n",
    "            \n",
    "            final_val_acc = metrics_log[\"val_accuracy\"][-1]\n",
    "            final_val_f1  = metrics_log[\"val_f1\"][-1]\n",
    "            results.append((final_val_acc, final_val_f1))\n",
    "        \n",
    "        results = np.array(results)\n",
    "        means = results.mean(axis=0)\n",
    "        stds  = results.std(axis=0)\n",
    "        print(\"\\n\\n======================= SUMMARY for {}% =======================\".format(cp))\n",
    "        print(f\"Validation Accuracy: mean={means[0]:.4f}, std={stds[0]:.4f}\")\n",
    "        print(f\"Validation F1:       mean={means[1]:.4f}, std={stds[1]:.4f}\")\n",
    "        overall_results[cp] = {\"mean\": means, \"std\": stds}\n",
    "    return overall_results\n",
    "\n",
    "\n",
    "def evaluate_propagation_quality(original_features, propagated_features):\n",
    "    original_features = original_features.cpu()\n",
    "    propagated_features = propagated_features.cpu()\n",
    "    \n",
    "    cosine_sim = F.cosine_similarity(original_features, propagated_features, dim=-1)\n",
    "    \n",
    "    mean_sim = cosine_sim.mean().item()\n",
    "    std_sim = cosine_sim.std().item()\n",
    "    min_sim = cosine_sim.min().item()\n",
    "    max_sim = cosine_sim.max().item()\n",
    "    \n",
    "    print(\"Propagation Quality Evaluation:\")\n",
    "    print(f\"Mean cosine similarity: {mean_sim:.4f}\")\n",
    "    print(f\"Std of cosine similarity: {std_sim:.4f}\")\n",
    "    print(f\"Min cosine similarity: {min_sim:.4f}\")\n",
    "    print(f\"Max cosine similarity: {max_sim:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(cosine_sim.numpy(), bins=50, alpha=0.75, color='skyblue', edgecolor='black')\n",
    "    plt.title(\"Histogram of Cosine Similarities\\nbetween Original and Propagated Embeddings\")\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "evaluate_propagation_quality(vit_train_features, propagated_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affinity_in_chunks(features, chunk_size=500):\n",
    "    N, d = features.shape\n",
    "    affinity = torch.empty((N, N), dtype=features.dtype)\n",
    "    for i in range(0, N, chunk_size):\n",
    "        end_i = min(i + chunk_size, N)\n",
    "        aff_chunk = F.cosine_similarity(features[i:end_i].unsqueeze(1),\n",
    "                                        features.unsqueeze(0), dim=-1)\n",
    "        aff_chunk = (aff_chunk + 1) / 2 # A_ij = cos(zi,zj) + 1 / 2\n",
    "        affinity[i:end_i] = aff_chunk\n",
    "    return affinity\n",
    "\n",
    "def compute_spectral_embedding(features, n_components=10, chunk_size=1000):\n",
    "    features = features.cpu()\n",
    "    N, d = features.shape\n",
    "    affinity = compute_affinity_in_chunks(features, chunk_size=chunk_size)\n",
    "    affinity.fill_diagonal_(0)  \n",
    "    D = affinity.sum(dim=1)\n",
    "    D_inv_sqrt = torch.diag(1.0 / torch.sqrt(D + 1e-8))\n",
    "    L = D_inv_sqrt @ affinity @ D_inv_sqrt  \n",
    "    eigvals, eigvecs = torch.linalg.eig(L)\n",
    "    eigvals = eigvals.real\n",
    "    eigvecs = eigvecs.real\n",
    "    sorted_indices = torch.argsort(eigvals, descending=True)\n",
    "    spectral_embedding = eigvecs[:, sorted_indices[:n_components]]\n",
    "    \n",
    "    return spectral_embedding\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_feat_path = \"vit_train_features.pth\"\n",
    "    val_feat_path   = \"vit_val_features.pth\"\n",
    "    test_feat_path  = \"vit_test_features.pth\"\n",
    "    \n",
    "    vit_train_features = torch.load(train_feat_path)\n",
    "    vit_val_features   = torch.load(val_feat_path)\n",
    "    vit_test_features  = torch.load(test_feat_path)\n",
    "    \n",
    "    spectral_train_embeddings = compute_spectral_embedding(vit_train_features, n_components=10)\n",
    "    spectral_val_embeddings   = compute_spectral_embedding(vit_val_features, n_components=10)\n",
    "    spectral_test_embeddings  = compute_spectral_embedding(vit_test_features, n_components=10)\n",
    "    \n",
    "    torch.save(spectral_train_embeddings, \"spectral_train_embeddings.pth\")\n",
    "    torch.save(spectral_val_embeddings,   \"spectral_val_embeddings.pth\")\n",
    "    torch.save(spectral_test_embeddings,  \"spectral_test_embeddings.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62479b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_spectral_coreset_selection_with_spectral_emb(spectral_embeddings, labels, percentage, random_state=42):\n",
    "    selected_indices = []\n",
    "    spectral_embeddings_np = spectral_embeddings.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    unique_labels = np.unique(labels_np)\n",
    "    \n",
    "    for cls in unique_labels:\n",
    "        cls_idx = np.where(labels_np == cls)[0]\n",
    "        X_cls = spectral_embeddings_np[cls_idx]  \n",
    "        n_cls = X_cls.shape[0]\n",
    "        n_sel = max(1, int(n_cls * (percentage / 100.0)))\n",
    "        \n",
    "        if n_sel >= n_cls:\n",
    "            selected_indices.extend(cls_idx.tolist())\n",
    "        elif n_sel == 1:\n",
    "            sim_matrix = cosine_similarity(X_cls)\n",
    "            avg_sim = sim_matrix.mean(axis=1)\n",
    "            medoid_idx = np.argmax(avg_sim)\n",
    "            selected_indices.append(cls_idx[medoid_idx])\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=n_sel, random_state=random_state)\n",
    "            cluster_labels = kmeans.fit_predict(X_cls)\n",
    "            for cluster in range(n_sel):\n",
    "                cluster_mask = (cluster_labels == cluster)\n",
    "                if np.sum(cluster_mask) == 0:\n",
    "                    continue\n",
    "                cluster_indices = np.where(cluster_mask)[0]\n",
    "                X_cluster = X_cls[cluster_indices]\n",
    "                sim_cluster = cosine_similarity(X_cluster)\n",
    "                avg_sim_cluster = sim_cluster.mean(axis=1)\n",
    "                medoid_in_cluster = cluster_indices[np.argmax(avg_sim_cluster)]\n",
    "                selected_indices.append(cls_idx[medoid_in_cluster])\n",
    "    \n",
    "    return np.array(selected_indices)\n",
    "\n",
    "\n",
    "def supervised_spectral_coreset_selection_for_dataset(dataset, spectral_embeddings, labels, percentage, random_state=42):\n",
    "    selected_idx = supervised_spectral_coreset_selection_with_spectral_emb(spectral_embeddings, labels, percentage, random_state)\n",
    "    return Subset(dataset, selected_idx)\n",
    "\n",
    "def load_datasubsets_spectral(img_size=224, batch_size=64, coreset_percentage=None, \n",
    "                               spectral_embeddings=None, vit_labels=None):\n",
    "    \"\"\"\n",
    "    Loads the train/val/test datasets and applies spectral coreset selection on the training set using\n",
    "    pre-computed spectral embeddings.\n",
    "    \"\"\"\n",
    "    train_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'train_images.npy'),\n",
    "        os.path.join(path, 'train_labels.npy'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "    if coreset_percentage is not None and spectral_embeddings is not None and vit_labels is not None:\n",
    "        train_dataset = supervised_spectral_coreset_selection_for_dataset(\n",
    "            train_dataset, spectral_embeddings, vit_labels, coreset_percentage, random_state=42\n",
    "        )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    val_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'val_images.npy'),\n",
    "        os.path.join(path, 'val_labels.npy'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    test_dataset = NumpyDataset(\n",
    "        os.path.join(path, 'test_images.npy'),\n",
    "        os.path.join(path, 'test_labels.npy'),\n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def run_spectral_coreset_experiments_derma_vgg(coreset_percentages=[0.1, 1, 10],\n",
    "                                     seeds=[42, 43, 45],\n",
    "                                     num_epochs=20,\n",
    "                                     learning_rate=0.0001,\n",
    "                                     batch_size=16,\n",
    "                                     img_size=224):\n",
    "    \"\"\"\n",
    "    Run experiments on coreset selection using pre-computed spectral embeddings.\n",
    "    \"\"\"\n",
    "    spectral_train_embeddings = torch.load(\"spectral_vgg_derma_train_embeddings.pth\")\n",
    "    vit_train_labels = torch.from_numpy(np.load(os.path.join(path, 'train_labels.npy'))).long()\n",
    "    \n",
    "    overall_results = {}\n",
    "    for cp in coreset_percentages:\n",
    "        print(f\"\\n\\n======================= Coreset Percentage: {cp}% =======================\")\n",
    "        results = []\n",
    "        for seed in seeds:\n",
    "            print(f\"\\n\\n----------------------- SEED {seed} -----------------------\")\n",
    "            set_seed(seed)\n",
    "            train_loader, val_loader, test_loader = load_datasubsets_spectral(\n",
    "                img_size=img_size,\n",
    "                batch_size=batch_size,\n",
    "                coreset_percentage=cp,\n",
    "                spectral_embeddings=spectral_train_embeddings,\n",
    "                vit_labels=vit_train_labels\n",
    "            )\n",
    "            \n",
    "            model = timm.create_model('vgg16', pretrained=True, num_classes=num_classes)\n",
    "            model = model.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                                   factor=0.1, patience=5, verbose=True)\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "            \n",
    "            metrics_log = train_model_subset(model, train_loader, val_loader, device,\n",
    "                                             optimizer, scheduler, scaler,\n",
    "                                             num_epochs=num_epochs)\n",
    "            \n",
    "            final_val_acc = metrics_log[\"val_accuracy\"][-1]\n",
    "            final_val_f1  = metrics_log[\"val_f1\"][-1]\n",
    "            results.append((final_val_acc, final_val_f1))\n",
    "        \n",
    "        results = np.array(results)\n",
    "        means = results.mean(axis=0)\n",
    "        stds  = results.std(axis=0)\n",
    "        print(f\"\\n\\n======================= SUMMARY for {cp}% =======================\")\n",
    "        print(f\"Validation Accuracy: mean={means[0]:.4f}, std={stds[0]:.4f}\")\n",
    "        print(f\"Validation F1:       mean={means[1]:.4f}, std={stds[1]:.4f}\")\n",
    "        overall_results[cp] = {\"mean\": means, \"std\": stds}\n",
    "    return overall_results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
